# COMPARE SHALLOW AND DEEP NEURAL NETWORKS FOR FUNCTION APPROXIMATION
In this project, we are interested in figuring out why
deep neural networks are preferable to shallow networks in function approximation
problems. We design experiments to prove that neural networks can achieve an approximation error
of Îµ uniformly over specific interval and the theorem holds even if the neural network has just a
single layer and an input and the output layer. We also design several experiments to compare the mean absolute error of deep networks and shallow
networks on univariate function and multivariate function approximation, and show that the performance of deep networks is better than shallow
networks given fixed number of neurons and trainable parameters. 

In this repo, experiment1 are univariate function approximation experiments, and experiment2&3 are multivariate function approximation experiments.

